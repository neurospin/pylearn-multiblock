<?xml version="1.0" encoding="ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>parsimony.functions.losses</title>
  <link rel="stylesheet" href="epydoc.css" type="text/css" />
  <script type="text/javascript" src="epydoc.js"></script>
</head>

<body bgcolor="white" text="black" link="blue" vlink="#204080"
      alink="#204080">
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="parsimony-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

      <th class="navbar" width="100%"></th>
  </tr>
</table>
<table width="100%" cellpadding="0" cellspacing="0">
  <tr valign="top">
    <td width="100%">
      <span class="breadcrumbs">
        <a href="parsimony-module.html">Package&nbsp;parsimony</a> ::
        <a href="parsimony.functions-module.html" onclick="show_private();">Package&nbsp;functions</a> ::
        Module&nbsp;losses
      </span>
    </td>
    <td>
      <table cellpadding="0" cellspacing="0">
        <!-- hide/show private -->
        <tr><td align="right"><span class="options">[<a href="javascript:void(0);" class="privatelink"
    onclick="toggle_private();">hide&nbsp;private</a>]</span></td></tr>
        <tr><td align="right"><span class="options"
            >[<a href="frames.html" target="_top">frames</a
            >]&nbsp;|&nbsp;<a href="parsimony.functions.losses-pysrc.html"
            target="_top">no&nbsp;frames</a>]</span></td></tr>
      </table>
    </td>
  </tr>
</table>
<h1 class="epydoc">Source Code for <a href="parsimony.functions.losses-module.html">Module parsimony.functions.losses</a></h1>
<pre class="py-src">
<a name="L1"></a><tt class="py-lineno">  1</tt>  <tt class="py-line"><tt class="py-comment"># -*- coding: utf-8 -*-</tt> </tt>
<a name="L2"></a><tt class="py-lineno">  2</tt>  <tt class="py-line"><tt class="py-docstring">"""</tt> </tt>
<a name="L3"></a><tt class="py-lineno">  3</tt>  <tt class="py-line"><tt class="py-docstring">The :mod:`parsimony.functions.loss` module contains the loss functions used</tt> </tt>
<a name="L4"></a><tt class="py-lineno">  4</tt>  <tt class="py-line"><tt class="py-docstring">throughout the package. These represent mathematical functions and should thus</tt> </tt>
<a name="L5"></a><tt class="py-lineno">  5</tt>  <tt class="py-line"><tt class="py-docstring">have properties used by the corresponding algorithms. These properties are</tt> </tt>
<a name="L6"></a><tt class="py-lineno">  6</tt>  <tt class="py-line"><tt class="py-docstring">defined in :mod:`parsimony.functions.interfaces`.</tt> </tt>
<a name="L7"></a><tt class="py-lineno">  7</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L8"></a><tt class="py-lineno">  8</tt>  <tt class="py-line"><tt class="py-docstring">Loss functions should be stateless. Loss functions may be shared and copied</tt> </tt>
<a name="L9"></a><tt class="py-lineno">  9</tt>  <tt class="py-line"><tt class="py-docstring">and should therefore not hold anything that cannot be recomputed the next time</tt> </tt>
<a name="L10"></a><tt class="py-lineno"> 10</tt>  <tt class="py-line"><tt class="py-docstring">it is called.</tt> </tt>
<a name="L11"></a><tt class="py-lineno"> 11</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L12"></a><tt class="py-lineno"> 12</tt>  <tt class="py-line"><tt class="py-docstring">Created on Mon Apr 22 10:54:29 2013</tt> </tt>
<a name="L13"></a><tt class="py-lineno"> 13</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L14"></a><tt class="py-lineno"> 14</tt>  <tt class="py-line"><tt class="py-docstring">@author:  Tommy L&#246;fstedt, Vincent Guillemot, Edouard Duchesnay and</tt> </tt>
<a name="L15"></a><tt class="py-lineno"> 15</tt>  <tt class="py-line"><tt class="py-docstring">          Fouad Hadj-Selem</tt> </tt>
<a name="L16"></a><tt class="py-lineno"> 16</tt>  <tt class="py-line"><tt class="py-docstring">@email:   lofstedt.tommy@gmail.com, edouard.duchesnay@cea.fr</tt> </tt>
<a name="L17"></a><tt class="py-lineno"> 17</tt>  <tt class="py-line"><tt class="py-docstring">@license: BSD 3-clause.</tt> </tt>
<a name="L18"></a><tt class="py-lineno"> 18</tt>  <tt class="py-line"><tt class="py-docstring">"""</tt> </tt>
<a name="L19"></a><tt class="py-lineno"> 19</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">numpy</tt> <tt class="py-keyword">as</tt> <tt class="py-name">np</tt> </tt>
<a name="L20"></a><tt class="py-lineno"> 20</tt>  <tt class="py-line"> </tt>
<a name="L21"></a><tt class="py-lineno"> 21</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-op">.</tt> <tt class="py-keyword">import</tt> <tt id="link-0" class="py-name" targets="Module parsimony.functions.interfaces=parsimony.functions.interfaces-module.html,Module parsimony.functions.multiblock.interfaces=parsimony.functions.multiblock.interfaces-module.html,Module parsimony.functions.nesterov.interfaces=parsimony.functions.nesterov.interfaces-module.html"><a title="parsimony.functions.interfaces
parsimony.functions.multiblock.interfaces
parsimony.functions.nesterov.interfaces" class="py-name" href="#" onclick="return doclink('link-0', 'interfaces', 'link-0');">interfaces</a></tt> </tt>
<a name="L22"></a><tt class="py-lineno"> 22</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt id="link-1" class="py-name" targets="Package parsimony=parsimony-module.html"><a title="parsimony" class="py-name" href="#" onclick="return doclink('link-1', 'parsimony', 'link-1');">parsimony</a></tt><tt class="py-op">.</tt><tt id="link-2" class="py-name" targets="Module parsimony.datasets.simulated.utils=parsimony.datasets.simulated.utils-module.html,Package parsimony.utils=parsimony.utils-module.html,Module parsimony.utils.utils=parsimony.utils.utils-module.html"><a title="parsimony.datasets.simulated.utils
parsimony.utils
parsimony.utils.utils" class="py-name" href="#" onclick="return doclink('link-2', 'utils', 'link-2');">utils</a></tt> <tt class="py-keyword">as</tt> <tt id="link-3" class="py-name"><a title="parsimony.datasets.simulated.utils
parsimony.utils
parsimony.utils.utils" class="py-name" href="#" onclick="return doclink('link-3', 'utils', 'link-2');">utils</a></tt> </tt>
<a name="L23"></a><tt class="py-lineno"> 23</tt>  <tt class="py-line"> </tt>
<a name="L24"></a><tt class="py-lineno"> 24</tt>  <tt class="py-line"><tt class="py-name">__all__</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-string">"RidgeRegression"</tt><tt class="py-op">,</tt> <tt class="py-string">"RidgeLogisticRegression"</tt><tt class="py-op">,</tt> <tt class="py-string">"AnonymousFunction"</tt><tt class="py-op">]</tt> </tt>
<a name="RidgeRegression"></a><div id="RidgeRegression-def"><a name="L25"></a><tt class="py-lineno"> 25</tt>  <tt class="py-line"> </tt>
<a name="L26"></a><tt class="py-lineno"> 26</tt>  <tt class="py-line"> </tt>
<a name="L27"></a><tt class="py-lineno"> 27</tt> <a class="py-toggle" href="#" id="RidgeRegression-toggle" onclick="return toggle('RidgeRegression');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html">RidgeRegression</a><tt class="py-op">(</tt><tt class="py-base-class">interfaces</tt><tt class="py-op">.</tt><tt class="py-base-class">CompositeFunction</tt><tt class="py-op">,</tt> </tt>
<a name="L28"></a><tt class="py-lineno"> 28</tt>  <tt class="py-line">                      <tt class="py-base-class">interfaces</tt><tt class="py-op">.</tt><tt class="py-base-class">Gradient</tt><tt class="py-op">,</tt> </tt>
<a name="L29"></a><tt class="py-lineno"> 29</tt>  <tt class="py-line">                      <tt class="py-base-class">interfaces</tt><tt class="py-op">.</tt><tt class="py-base-class">LipschitzContinuousGradient</tt><tt class="py-op">,</tt> </tt>
<a name="L30"></a><tt class="py-lineno"> 30</tt>  <tt class="py-line">                      <tt class="py-base-class">interfaces</tt><tt class="py-op">.</tt><tt class="py-base-class">Eigenvalues</tt><tt class="py-op">,</tt> </tt>
<a name="L31"></a><tt class="py-lineno"> 31</tt>  <tt class="py-line">                      <tt class="py-base-class">interfaces</tt><tt class="py-op">.</tt><tt class="py-base-class">StronglyConvex</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="RidgeRegression-expanded"><a name="L32"></a><tt class="py-lineno"> 32</tt>  <tt class="py-line">    <tt class="py-docstring">""" The Ridge Regression function</tt> </tt>
<a name="L33"></a><tt class="py-lineno"> 33</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L34"></a><tt class="py-lineno"> 34</tt>  <tt class="py-line"><tt class="py-docstring">    Parameters</tt> </tt>
<a name="L35"></a><tt class="py-lineno"> 35</tt>  <tt class="py-line"><tt class="py-docstring">    ----------</tt> </tt>
<a name="L36"></a><tt class="py-lineno"> 36</tt>  <tt class="py-line"><tt class="py-docstring">    X : Numpy array (n-by-p). The regressor matrix.</tt> </tt>
<a name="L37"></a><tt class="py-lineno"> 37</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L38"></a><tt class="py-lineno"> 38</tt>  <tt class="py-line"><tt class="py-docstring">    y : Numpy array (n-by-1). The regressand vector.</tt> </tt>
<a name="L39"></a><tt class="py-lineno"> 39</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L40"></a><tt class="py-lineno"> 40</tt>  <tt class="py-line"><tt class="py-docstring">    k : Non-negative float. The ridge parameter.</tt> </tt>
<a name="L41"></a><tt class="py-lineno"> 41</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="RidgeRegression.__init__"></a><div id="RidgeRegression.__init__-def"><a name="L42"></a><tt class="py-lineno"> 42</tt> <a class="py-toggle" href="#" id="RidgeRegression.__init__-toggle" onclick="return toggle('RidgeRegression.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">X</tt><tt class="py-op">,</tt> <tt class="py-param">y</tt><tt class="py-op">,</tt> <tt class="py-param">k</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.__init__-expanded"><a name="L43"></a><tt class="py-lineno"> 43</tt>  <tt class="py-line"> </tt>
<a name="L44"></a><tt class="py-lineno"> 44</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt> <tt class="py-op">=</tt> <tt class="py-name">X</tt> </tt>
<a name="L45"></a><tt class="py-lineno"> 45</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt> <tt class="py-op">=</tt> <tt class="py-name">y</tt> </tt>
<a name="L46"></a><tt class="py-lineno"> 46</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">=</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">k</tt><tt class="py-op">)</tt> </tt>
<a name="L47"></a><tt class="py-lineno"> 47</tt>  <tt class="py-line"> </tt>
<a name="L48"></a><tt class="py-lineno"> 48</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-4" class="py-name" targets="Method parsimony._functions.Function.reset()=parsimony._functions.Function-class.html#reset,Method parsimony._functions.GeneralisedMultiblock.reset()=parsimony._functions.GeneralisedMultiblock-class.html#reset,Method parsimony._functions.GroupLassoOverlap.reset()=parsimony._functions.GroupLassoOverlap-class.html#reset,Method parsimony._functions.LatentVariableCovariance.reset()=parsimony._functions.LatentVariableCovariance-class.html#reset,Method parsimony._functions.RGCCAConstraint.reset()=parsimony._functions.RGCCAConstraint-class.html#reset,Method parsimony._functions.RR_L1_GL.reset()=parsimony._functions.RR_L1_GL-class.html#reset,Method parsimony._functions.RR_L1_TV.reset()=parsimony._functions.RR_L1_TV-class.html#reset,Method parsimony._functions.RR_SmoothedL1TV.reset()=parsimony._functions.RR_SmoothedL1TV-class.html#reset,Method parsimony._functions.RidgeLogisticRegression.reset()=parsimony._functions.RidgeLogisticRegression-class.html#reset,Method parsimony._functions.RidgeRegression.reset()=parsimony._functions.RidgeRegression-class.html#reset,Method parsimony._functions.SmoothedL1TV.reset()=parsimony._functions.SmoothedL1TV-class.html#reset,Method parsimony._functions.TotalVariation.reset()=parsimony._functions.TotalVariation-class.html#reset,Method parsimony.functions.interfaces.Function.reset()=parsimony.functions.interfaces.Function-class.html#reset,Method parsimony.functions.losses.RidgeLogisticRegression.reset()=parsimony.functions.losses.RidgeLogisticRegression-class.html#reset,Method parsimony.functions.losses.RidgeRegression.reset()=parsimony.functions.losses.RidgeRegression-class.html#reset,Method parsimony.functions.multiblock.losses.GeneralisedMultiblock.reset()=parsimony.functions.multiblock.losses.GeneralisedMultiblock-class.html#reset,Method parsimony.functions.multiblock.losses.LatentVariableCovariance.reset()=parsimony.functions.multiblock.losses.LatentVariableCovariance-class.html#reset,Method parsimony.functions.nesterov.L1TV.L1TV.reset()=parsimony.functions.nesterov.L1TV.L1TV-class.html#reset,Method parsimony.functions.nesterov.gl.GroupLassoOverlap.reset()=parsimony.functions.nesterov.gl.GroupLassoOverlap-class.html#reset,Method parsimony.functions.nesterov.tv.TotalVariation.reset()=parsimony.functions.nesterov.tv.TotalVariation-class.html#reset,Method parsimony.functions.objectives.functions.CombinedFunction.reset()=parsimony.functions.objectives.functions.CombinedFunction-class.html#reset,Method parsimony.functions.objectives.functions.RR_L1_GL.reset()=parsimony.functions.objectives.functions.RR_L1_GL-class.html#reset,Method parsimony.functions.objectives.functions.RR_L1_TV.reset()=parsimony.functions.objectives.functions.RR_L1_TV-class.html#reset,Method parsimony.functions.objectives.functions.RR_SmoothedL1TV.reset()=parsimony.functions.objectives.functions.RR_SmoothedL1TV-class.html#reset,Method parsimony.functions.penalties.RGCCAConstraint.reset()=parsimony.functions.penalties.RGCCAConstraint-class.html#reset,Method parsimony.functions.penalties.ZeroFunction.reset()=parsimony.functions.penalties.ZeroFunction-class.html#reset"><a title="parsimony._functions.Function.reset
parsimony._functions.GeneralisedMultiblock.reset
parsimony._functions.GroupLassoOverlap.reset
parsimony._functions.LatentVariableCovariance.reset
parsimony._functions.RGCCAConstraint.reset
parsimony._functions.RR_L1_GL.reset
parsimony._functions.RR_L1_TV.reset
parsimony._functions.RR_SmoothedL1TV.reset
parsimony._functions.RidgeLogisticRegression.reset
parsimony._functions.RidgeRegression.reset
parsimony._functions.SmoothedL1TV.reset
parsimony._functions.TotalVariation.reset
parsimony.functions.interfaces.Function.reset
parsimony.functions.losses.RidgeLogisticRegression.reset
parsimony.functions.losses.RidgeRegression.reset
parsimony.functions.multiblock.losses.GeneralisedMultiblock.reset
parsimony.functions.multiblock.losses.LatentVariableCovariance.reset
parsimony.functions.nesterov.L1TV.L1TV.reset
parsimony.functions.nesterov.gl.GroupLassoOverlap.reset
parsimony.functions.nesterov.tv.TotalVariation.reset
parsimony.functions.objectives.functions.CombinedFunction.reset
parsimony.functions.objectives.functions.RR_L1_GL.reset
parsimony.functions.objectives.functions.RR_L1_TV.reset
parsimony.functions.objectives.functions.RR_SmoothedL1TV.reset
parsimony.functions.penalties.RGCCAConstraint.reset
parsimony.functions.penalties.ZeroFunction.reset" class="py-name" href="#" onclick="return doclink('link-4', 'reset', 'link-4');">reset</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L49"></a><tt class="py-lineno"> 49</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression.reset"></a><div id="RidgeRegression.reset-def"><a name="L50"></a><tt class="py-lineno"> 50</tt> <a class="py-toggle" href="#" id="RidgeRegression.reset-toggle" onclick="return toggle('RidgeRegression.reset');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#reset">reset</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.reset-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.reset-expanded"><a name="L51"></a><tt class="py-lineno"> 51</tt>  <tt class="py-line">        <tt class="py-docstring">"""Reset the value of _lambda_max and _lambda_min</tt> </tt>
<a name="L52"></a><tt class="py-lineno"> 52</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L53"></a><tt class="py-lineno"> 53</tt>  <tt class="py-line"> </tt>
<a name="L54"></a><tt class="py-lineno"> 54</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
<a name="L55"></a><tt class="py-lineno"> 55</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
</div><a name="L56"></a><tt class="py-lineno"> 56</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression.f"></a><div id="RidgeRegression.f-def"><a name="L57"></a><tt class="py-lineno"> 57</tt> <a class="py-toggle" href="#" id="RidgeRegression.f-toggle" onclick="return toggle('RidgeRegression.f');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#f">f</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.f-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.f-expanded"><a name="L58"></a><tt class="py-lineno"> 58</tt>  <tt class="py-line">        <tt class="py-docstring">"""Function value of Ridge regression.</tt> </tt>
<a name="L59"></a><tt class="py-lineno"> 59</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L60"></a><tt class="py-lineno"> 60</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L61"></a><tt class="py-lineno"> 61</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L62"></a><tt class="py-lineno"> 62</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Regression coefficient vector</tt> </tt>
<a name="L63"></a><tt class="py-lineno"> 63</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L64"></a><tt class="py-lineno"> 64</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">(</tt><tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt id="link-5" class="py-name" targets="Module parsimony.datasets.simulated.beta=parsimony.datasets.simulated.beta-module.html"><a title="parsimony.datasets.simulated.beta" class="py-name" href="#" onclick="return doclink('link-5', 'beta', 'link-5');">beta</a></tt><tt class="py-op">)</tt> <tt class="py-op">-</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> \ </tt>
<a name="L65"></a><tt class="py-lineno"> 65</tt>  <tt class="py-line">             <tt class="py-op">+</tt> <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">/</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt id="link-6" class="py-name"><a title="parsimony.datasets.simulated.beta" class="py-name" href="#" onclick="return doclink('link-6', 'beta', 'link-5');">beta</a></tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> </tt>
</div><a name="L66"></a><tt class="py-lineno"> 66</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression.grad"></a><div id="RidgeRegression.grad-def"><a name="L67"></a><tt class="py-lineno"> 67</tt> <a class="py-toggle" href="#" id="RidgeRegression.grad-toggle" onclick="return toggle('RidgeRegression.grad');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#grad">grad</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.grad-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.grad-expanded"><a name="L68"></a><tt class="py-lineno"> 68</tt>  <tt class="py-line">        <tt class="py-docstring">"""Gradient of the function at beta.</tt> </tt>
<a name="L69"></a><tt class="py-lineno"> 69</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L70"></a><tt class="py-lineno"> 70</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Gradient".</tt> </tt>
<a name="L71"></a><tt class="py-lineno"> 71</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L72"></a><tt class="py-lineno"> 72</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L73"></a><tt class="py-lineno"> 73</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L74"></a><tt class="py-lineno"> 74</tt>  <tt class="py-line"><tt class="py-docstring">        beta : The point at which to evaluate the gradient.</tt> </tt>
<a name="L75"></a><tt class="py-lineno"> 75</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L76"></a><tt class="py-lineno"> 76</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt id="link-7" class="py-name"><a title="parsimony.datasets.simulated.beta" class="py-name" href="#" onclick="return doclink('link-7', 'beta', 'link-5');">beta</a></tt><tt class="py-op">)</tt> <tt class="py-op">-</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">T</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">T</tt> \ </tt>
<a name="L77"></a><tt class="py-lineno"> 77</tt>  <tt class="py-line">             <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">*</tt> <tt id="link-8" class="py-name"><a title="parsimony.datasets.simulated.beta" class="py-name" href="#" onclick="return doclink('link-8', 'beta', 'link-5');">beta</a></tt> </tt>
</div><a name="L78"></a><tt class="py-lineno"> 78</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression.L"></a><div id="RidgeRegression.L-def"><a name="L79"></a><tt class="py-lineno"> 79</tt> <a class="py-toggle" href="#" id="RidgeRegression.L-toggle" onclick="return toggle('RidgeRegression.L');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#L">L</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.L-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.L-expanded"><a name="L80"></a><tt class="py-lineno"> 80</tt>  <tt class="py-line">        <tt class="py-docstring">"""Lipschitz constant of the gradient.</tt> </tt>
<a name="L81"></a><tt class="py-lineno"> 81</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L82"></a><tt class="py-lineno"> 82</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "LipschitzContinuousGradient".</tt> </tt>
<a name="L83"></a><tt class="py-lineno"> 83</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L84"></a><tt class="py-lineno"> 84</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-9" class="py-name" targets="Method parsimony._functions.Eigenvalues.lambda_max()=parsimony._functions.Eigenvalues-class.html#lambda_max,Method parsimony._functions.GroupLassoOverlap.lambda_max()=parsimony._functions.GroupLassoOverlap-class.html#lambda_max,Method parsimony._functions.LatentVariableCovariance.lambda_max()=parsimony._functions.LatentVariableCovariance-class.html#lambda_max,Method parsimony._functions.RidgeRegression.lambda_max()=parsimony._functions.RidgeRegression-class.html#lambda_max,Method parsimony._functions.SmoothedL1TV.lambda_max()=parsimony._functions.SmoothedL1TV-class.html#lambda_max,Method parsimony._functions.TotalVariation.lambda_max()=parsimony._functions.TotalVariation-class.html#lambda_max,Method parsimony.functions.interfaces.Eigenvalues.lambda_max()=parsimony.functions.interfaces.Eigenvalues-class.html#lambda_max,Method parsimony.functions.losses.RidgeRegression.lambda_max()=parsimony.functions.losses.RidgeRegression-class.html#lambda_max,Method parsimony.functions.multiblock.losses.LatentVariableCovariance.lambda_max()=parsimony.functions.multiblock.losses.LatentVariableCovariance-class.html#lambda_max,Method parsimony.functions.nesterov.L1TV.L1TV.lambda_max()=parsimony.functions.nesterov.L1TV.L1TV-class.html#lambda_max,Method parsimony.functions.nesterov.gl.GroupLassoOverlap.lambda_max()=parsimony.functions.nesterov.gl.GroupLassoOverlap-class.html#lambda_max,Method parsimony.functions.nesterov.tv.TotalVariation.lambda_max()=parsimony.functions.nesterov.tv.TotalVariation-class.html#lambda_max"><a title="parsimony._functions.Eigenvalues.lambda_max
parsimony._functions.GroupLassoOverlap.lambda_max
parsimony._functions.LatentVariableCovariance.lambda_max
parsimony._functions.RidgeRegression.lambda_max
parsimony._functions.SmoothedL1TV.lambda_max
parsimony._functions.TotalVariation.lambda_max
parsimony.functions.interfaces.Eigenvalues.lambda_max
parsimony.functions.losses.RidgeRegression.lambda_max
parsimony.functions.multiblock.losses.LatentVariableCovariance.lambda_max
parsimony.functions.nesterov.L1TV.L1TV.lambda_max
parsimony.functions.nesterov.gl.GroupLassoOverlap.lambda_max
parsimony.functions.nesterov.tv.TotalVariation.lambda_max" class="py-name" href="#" onclick="return doclink('link-9', 'lambda_max', 'link-9');">lambda_max</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L85"></a><tt class="py-lineno"> 85</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression.lambda_max"></a><div id="RidgeRegression.lambda_max-def"><a name="L86"></a><tt class="py-lineno"> 86</tt> <a class="py-toggle" href="#" id="RidgeRegression.lambda_max-toggle" onclick="return toggle('RidgeRegression.lambda_max');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#lambda_max">lambda_max</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.lambda_max-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.lambda_max-expanded"><a name="L87"></a><tt class="py-lineno"> 87</tt>  <tt class="py-line">        <tt class="py-docstring">"""Largest eigenvalue of the corresponding covariance matrix.</tt> </tt>
<a name="L88"></a><tt class="py-lineno"> 88</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L89"></a><tt class="py-lineno"> 89</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Eigenvalues".</tt> </tt>
<a name="L90"></a><tt class="py-lineno"> 90</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L91"></a><tt class="py-lineno"> 91</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L92"></a><tt class="py-lineno"> 92</tt>  <tt class="py-line">            <tt class="py-name">s</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">linalg</tt><tt class="py-op">.</tt><tt class="py-name">svd</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt class="py-name">full_matrices</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">,</tt> <tt class="py-name">compute_uv</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt> </tt>
<a name="L93"></a><tt class="py-lineno"> 93</tt>  <tt class="py-line"> </tt>
<a name="L94"></a><tt class="py-lineno"> 94</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt> </tt>
<a name="L95"></a><tt class="py-lineno"> 95</tt>  <tt class="py-line"> </tt>
<a name="L96"></a><tt class="py-lineno"> 96</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">&lt;</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">:</tt> </tt>
<a name="L97"></a><tt class="py-lineno"> 97</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">=</tt> <tt class="py-number">0.0</tt> </tt>
<a name="L98"></a><tt class="py-lineno"> 98</tt>  <tt class="py-line">            <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L99"></a><tt class="py-lineno"> 99</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">min</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt> </tt>
<a name="L100"></a><tt class="py-lineno">100</tt>  <tt class="py-line"> </tt>
<a name="L101"></a><tt class="py-lineno">101</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> </tt>
</div><a name="L102"></a><tt class="py-lineno">102</tt>  <tt class="py-line"> </tt>
<a name="L103"></a><tt class="py-lineno">103</tt>  <tt class="py-line">    <tt class="py-decorator">@</tt><tt class="py-decorator">utils</tt><tt class="py-op">.</tt><tt id="link-10" class="py-name" targets="Function parsimony.utils.utils.deprecated()=parsimony.utils.utils-module.html#deprecated"><a title="parsimony.utils.utils.deprecated" class="py-name" href="#" onclick="return doclink('link-10', 'deprecated', 'link-10');">deprecated</a></tt><tt class="py-op">(</tt><tt class="py-string">"StronglyConvex.parameter"</tt><tt class="py-op">)</tt> </tt>
<a name="RidgeRegression.lambda_min"></a><div id="RidgeRegression.lambda_min-def"><a name="L104"></a><tt class="py-lineno">104</tt> <a class="py-toggle" href="#" id="RidgeRegression.lambda_min-toggle" onclick="return toggle('RidgeRegression.lambda_min');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#lambda_min">lambda_min</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.lambda_min-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.lambda_min-expanded"><a name="L105"></a><tt class="py-lineno">105</tt>  <tt class="py-line">        <tt class="py-docstring">"""Smallest eigenvalue of the corresponding covariance matrix.</tt> </tt>
<a name="L106"></a><tt class="py-lineno">106</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L107"></a><tt class="py-lineno">107</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Eigenvalues".</tt> </tt>
<a name="L108"></a><tt class="py-lineno">108</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L109"></a><tt class="py-lineno">109</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L110"></a><tt class="py-lineno">110</tt>  <tt class="py-line">            <tt class="py-name">s</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">linalg</tt><tt class="py-op">.</tt><tt class="py-name">svd</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt class="py-name">full_matrices</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">,</tt> <tt class="py-name">compute_uv</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt> </tt>
<a name="L111"></a><tt class="py-lineno">111</tt>  <tt class="py-line"> </tt>
<a name="L112"></a><tt class="py-lineno">112</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt> </tt>
<a name="L113"></a><tt class="py-lineno">113</tt>  <tt class="py-line"> </tt>
<a name="L114"></a><tt class="py-lineno">114</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">&lt;</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">:</tt> </tt>
<a name="L115"></a><tt class="py-lineno">115</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">=</tt> <tt class="py-number">0.0</tt> </tt>
<a name="L116"></a><tt class="py-lineno">116</tt>  <tt class="py-line">            <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L117"></a><tt class="py-lineno">117</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">min</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt> </tt>
<a name="L118"></a><tt class="py-lineno">118</tt>  <tt class="py-line"> </tt>
<a name="L119"></a><tt class="py-lineno">119</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> </tt>
</div><a name="L120"></a><tt class="py-lineno">120</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression.parameter"></a><div id="RidgeRegression.parameter-def"><a name="L121"></a><tt class="py-lineno">121</tt> <a class="py-toggle" href="#" id="RidgeRegression.parameter-toggle" onclick="return toggle('RidgeRegression.parameter');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#parameter">parameter</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.parameter-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.parameter-expanded"><a name="L122"></a><tt class="py-lineno">122</tt>  <tt class="py-line">        <tt class="py-docstring">"""Returns the strongly convex parameter for the function.</tt> </tt>
<a name="L123"></a><tt class="py-lineno">123</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L124"></a><tt class="py-lineno">124</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "StronglyConvex".</tt> </tt>
<a name="L125"></a><tt class="py-lineno">125</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L126"></a><tt class="py-lineno">126</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L127"></a><tt class="py-lineno">127</tt>  <tt class="py-line">            <tt class="py-name">s</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">linalg</tt><tt class="py-op">.</tt><tt class="py-name">svd</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt class="py-name">full_matrices</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">,</tt> <tt class="py-name">compute_uv</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt> </tt>
<a name="L128"></a><tt class="py-lineno">128</tt>  <tt class="py-line"> </tt>
<a name="L129"></a><tt class="py-lineno">129</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt> </tt>
<a name="L130"></a><tt class="py-lineno">130</tt>  <tt class="py-line"> </tt>
<a name="L131"></a><tt class="py-lineno">131</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">&lt;</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">:</tt> </tt>
<a name="L132"></a><tt class="py-lineno">132</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">=</tt> <tt class="py-number">0.0</tt> </tt>
<a name="L133"></a><tt class="py-lineno">133</tt>  <tt class="py-line">            <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L134"></a><tt class="py-lineno">134</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">min</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt> </tt>
<a name="L135"></a><tt class="py-lineno">135</tt>  <tt class="py-line"> </tt>
<a name="L136"></a><tt class="py-lineno">136</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> </tt>
</div></div><a name="L137"></a><tt class="py-lineno">137</tt>  <tt class="py-line"> </tt>
<a name="RidgeLogisticRegression"></a><div id="RidgeLogisticRegression-def"><a name="L138"></a><tt class="py-lineno">138</tt>  <tt class="py-line"> </tt>
<a name="L139"></a><tt class="py-lineno">139</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression-toggle" onclick="return toggle('RidgeLogisticRegression');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html">RidgeLogisticRegression</a><tt class="py-op">(</tt><tt class="py-base-class">interfaces</tt><tt class="py-op">.</tt><tt class="py-base-class">CompositeFunction</tt><tt class="py-op">,</tt> </tt>
<a name="L140"></a><tt class="py-lineno">140</tt>  <tt class="py-line">                              <tt class="py-base-class">interfaces</tt><tt class="py-op">.</tt><tt class="py-base-class">Gradient</tt><tt class="py-op">,</tt> </tt>
<a name="L141"></a><tt class="py-lineno">141</tt>  <tt class="py-line">                              <tt class="py-base-class">interfaces</tt><tt class="py-op">.</tt><tt class="py-base-class">LipschitzContinuousGradient</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="RidgeLogisticRegression-expanded"><a name="L142"></a><tt class="py-lineno">142</tt>  <tt class="py-line">    <tt class="py-docstring">""" The Logistic Regression function.</tt> </tt>
<a name="L143"></a><tt class="py-lineno">143</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L144"></a><tt class="py-lineno">144</tt>  <tt class="py-line"><tt class="py-docstring">    Ridge (re-weighted) log-likelihood (cross-entropy):</tt> </tt>
<a name="L145"></a><tt class="py-lineno">145</tt>  <tt class="py-line"><tt class="py-docstring">    * f(beta) = -Sum wi (yi log(pi) + (1 &#8722; yi) log(1 &#8722; pi)) + k/2 ||beta||^2_2</tt> </tt>
<a name="L146"></a><tt class="py-lineno">146</tt>  <tt class="py-line"><tt class="py-docstring">              = -Sum wi (yi xi' beta &#8722; log(1 + e(xi' beta))) + k/2 ||beta||^2_2</tt> </tt>
<a name="L147"></a><tt class="py-lineno">147</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L148"></a><tt class="py-lineno">148</tt>  <tt class="py-line"><tt class="py-docstring">    * grad f(beta) = -Sum wi[ xi (yi - pi)] + k beta</tt> </tt>
<a name="L149"></a><tt class="py-lineno">149</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L150"></a><tt class="py-lineno">150</tt>  <tt class="py-line"><tt class="py-docstring">    pi = p(y=1|xi, beta) = 1 / (1 + exp(-xi' beta))</tt> </tt>
<a name="L151"></a><tt class="py-lineno">151</tt>  <tt class="py-line"><tt class="py-docstring">    wi: sample i weight</tt> </tt>
<a name="L152"></a><tt class="py-lineno">152</tt>  <tt class="py-line"><tt class="py-docstring">    [Hastie 2009, p.: 102, 119 and 161, Bishop 2006 p.: 206]</tt> </tt>
<a name="L153"></a><tt class="py-lineno">153</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L154"></a><tt class="py-lineno">154</tt>  <tt class="py-line"><tt class="py-docstring">    Parameters</tt> </tt>
<a name="L155"></a><tt class="py-lineno">155</tt>  <tt class="py-line"><tt class="py-docstring">    ----------</tt> </tt>
<a name="L156"></a><tt class="py-lineno">156</tt>  <tt class="py-line"><tt class="py-docstring">    X : Numpy array (n-by-p). The regressor matrix.</tt> </tt>
<a name="L157"></a><tt class="py-lineno">157</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L158"></a><tt class="py-lineno">158</tt>  <tt class="py-line"><tt class="py-docstring">    y : Numpy array (n-by-1). The regressand vector.</tt> </tt>
<a name="L159"></a><tt class="py-lineno">159</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L160"></a><tt class="py-lineno">160</tt>  <tt class="py-line"><tt class="py-docstring">    weights: Numpy array (n-by-1). The sample's weights.</tt> </tt>
<a name="L161"></a><tt class="py-lineno">161</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="RidgeLogisticRegression.__init__"></a><div id="RidgeLogisticRegression.__init__-def"><a name="L162"></a><tt class="py-lineno">162</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression.__init__-toggle" onclick="return toggle('RidgeLogisticRegression.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">X</tt><tt class="py-op">,</tt> <tt class="py-param">y</tt><tt class="py-op">,</tt> <tt class="py-param">k</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-param">weights</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeLogisticRegression.__init__-expanded"><a name="L163"></a><tt class="py-lineno">163</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt> <tt class="py-op">=</tt> <tt class="py-name">X</tt> </tt>
<a name="L164"></a><tt class="py-lineno">164</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt> <tt class="py-op">=</tt> <tt class="py-name">y</tt> </tt>
<a name="L165"></a><tt class="py-lineno">165</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">=</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">k</tt><tt class="py-op">)</tt> </tt>
<a name="L166"></a><tt class="py-lineno">166</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">weights</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L167"></a><tt class="py-lineno">167</tt>  <tt class="py-line">            <tt class="py-comment"># TODO: Make the weights sparse.</tt> </tt>
<a name="L168"></a><tt class="py-lineno">168</tt>  <tt class="py-line">            <tt class="py-comment">#weights = np.eye(self.X.shape[0])</tt> </tt>
<a name="L169"></a><tt class="py-lineno">169</tt>  <tt class="py-line">            <tt class="py-name">weights</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">ones</tt><tt class="py-op">(</tt><tt class="py-name">y</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">y</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">)</tt> </tt>
<a name="L170"></a><tt class="py-lineno">170</tt>  <tt class="py-line">        <tt class="py-comment"># TODO: Allow the weight vector to be a list.</tt> </tt>
<a name="L171"></a><tt class="py-lineno">171</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">weights</tt> <tt class="py-op">=</tt> <tt class="py-name">weights</tt> </tt>
<a name="L172"></a><tt class="py-lineno">172</tt>  <tt class="py-line"> </tt>
<a name="L173"></a><tt class="py-lineno">173</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-11" class="py-name"><a title="parsimony._functions.Function.reset
parsimony._functions.GeneralisedMultiblock.reset
parsimony._functions.GroupLassoOverlap.reset
parsimony._functions.LatentVariableCovariance.reset
parsimony._functions.RGCCAConstraint.reset
parsimony._functions.RR_L1_GL.reset
parsimony._functions.RR_L1_TV.reset
parsimony._functions.RR_SmoothedL1TV.reset
parsimony._functions.RidgeLogisticRegression.reset
parsimony._functions.RidgeRegression.reset
parsimony._functions.SmoothedL1TV.reset
parsimony._functions.TotalVariation.reset
parsimony.functions.interfaces.Function.reset
parsimony.functions.losses.RidgeLogisticRegression.reset
parsimony.functions.losses.RidgeRegression.reset
parsimony.functions.multiblock.losses.GeneralisedMultiblock.reset
parsimony.functions.multiblock.losses.LatentVariableCovariance.reset
parsimony.functions.nesterov.L1TV.L1TV.reset
parsimony.functions.nesterov.gl.GroupLassoOverlap.reset
parsimony.functions.nesterov.tv.TotalVariation.reset
parsimony.functions.objectives.functions.CombinedFunction.reset
parsimony.functions.objectives.functions.RR_L1_GL.reset
parsimony.functions.objectives.functions.RR_L1_TV.reset
parsimony.functions.objectives.functions.RR_SmoothedL1TV.reset
parsimony.functions.penalties.RGCCAConstraint.reset
parsimony.functions.penalties.ZeroFunction.reset" class="py-name" href="#" onclick="return doclink('link-11', 'reset', 'link-4');">reset</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L174"></a><tt class="py-lineno">174</tt>  <tt class="py-line"> </tt>
<a name="RidgeLogisticRegression.reset"></a><div id="RidgeLogisticRegression.reset-def"><a name="L175"></a><tt class="py-lineno">175</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression.reset-toggle" onclick="return toggle('RidgeLogisticRegression.reset');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html#reset">reset</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression.reset-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeLogisticRegression.reset-expanded"><a name="L176"></a><tt class="py-lineno">176</tt>  <tt class="py-line">        <tt class="py-docstring">"""Reset the value of _lambda_max and _lambda_min</tt> </tt>
<a name="L177"></a><tt class="py-lineno">177</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L178"></a><tt class="py-lineno">178</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">lipschitz</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
</div><a name="L179"></a><tt class="py-lineno">179</tt>  <tt class="py-line"><tt class="py-comment">#        self._lambda_max = None</tt> </tt>
<a name="L180"></a><tt class="py-lineno">180</tt>  <tt class="py-line"><tt class="py-comment">#        self._lambda_min = None</tt> </tt>
<a name="L181"></a><tt class="py-lineno">181</tt>  <tt class="py-line"> </tt>
<a name="RidgeLogisticRegression.f"></a><div id="RidgeLogisticRegression.f-def"><a name="L182"></a><tt class="py-lineno">182</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression.f-toggle" onclick="return toggle('RidgeLogisticRegression.f');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html#f">f</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression.f-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeLogisticRegression.f-expanded"><a name="L183"></a><tt class="py-lineno">183</tt>  <tt class="py-line">        <tt class="py-docstring">"""Function value of Logistic regression at beta.</tt> </tt>
<a name="L184"></a><tt class="py-lineno">184</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L185"></a><tt class="py-lineno">185</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L186"></a><tt class="py-lineno">186</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L187"></a><tt class="py-lineno">187</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Regression coefficient vector</tt> </tt>
<a name="L188"></a><tt class="py-lineno">188</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L189"></a><tt class="py-lineno">189</tt>  <tt class="py-line">        <tt class="py-comment"># TODO check the correctness of the re-weighted loglike</tt> </tt>
<a name="L190"></a><tt class="py-lineno">190</tt>  <tt class="py-line">        <tt class="py-name">Xbeta</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt id="link-12" class="py-name"><a title="parsimony.datasets.simulated.beta" class="py-name" href="#" onclick="return doclink('link-12', 'beta', 'link-5');">beta</a></tt><tt class="py-op">)</tt> </tt>
<a name="L191"></a><tt class="py-lineno">191</tt>  <tt class="py-line">        <tt class="py-name">loglike</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">weights</tt> <tt class="py-op">*</tt> </tt>
<a name="L192"></a><tt class="py-lineno">192</tt>  <tt class="py-line">            <tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt> <tt class="py-op">*</tt> <tt class="py-name">Xbeta</tt><tt class="py-op">)</tt> <tt class="py-op">-</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">log</tt><tt class="py-op">(</tt><tt class="py-number">1</tt> <tt class="py-op">+</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">exp</tt><tt class="py-op">(</tt><tt class="py-name">Xbeta</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L193"></a><tt class="py-lineno">193</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">-</tt><tt class="py-name">loglike</tt> <tt class="py-op">+</tt> <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">/</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt id="link-13" class="py-name"><a title="parsimony.datasets.simulated.beta" class="py-name" href="#" onclick="return doclink('link-13', 'beta', 'link-5');">beta</a></tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> </tt>
</div><a name="L194"></a><tt class="py-lineno">194</tt>  <tt class="py-line"><tt class="py-comment">#        n = self.X.shape[0]</tt> </tt>
<a name="L195"></a><tt class="py-lineno">195</tt>  <tt class="py-line"><tt class="py-comment">#        s = 0</tt> </tt>
<a name="L196"></a><tt class="py-lineno">196</tt>  <tt class="py-line"><tt class="py-comment">#        for i in xrange(n):</tt> </tt>
<a name="L197"></a><tt class="py-lineno">197</tt>  <tt class="py-line"><tt class="py-comment">#            s = s + self.W[i, i] * (self.y[i, 0] * Xbeta[i, 0] \</tt> </tt>
<a name="L198"></a><tt class="py-lineno">198</tt>  <tt class="py-line"><tt class="py-comment">#                                    - np.log(1 + np.exp(Xbeta[i, 0])))</tt> </tt>
<a name="L199"></a><tt class="py-lineno">199</tt>  <tt class="py-line"><tt class="py-comment">#        return -s  + (self.k / 2.0) * np.sum(beta ** 2.0) ## TOCHECK</tt> </tt>
<a name="L200"></a><tt class="py-lineno">200</tt>  <tt class="py-line"> </tt>
<a name="RidgeLogisticRegression.grad"></a><div id="RidgeLogisticRegression.grad-def"><a name="L201"></a><tt class="py-lineno">201</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression.grad-toggle" onclick="return toggle('RidgeLogisticRegression.grad');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html#grad">grad</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression.grad-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeLogisticRegression.grad-expanded"><a name="L202"></a><tt class="py-lineno">202</tt>  <tt class="py-line">        <tt class="py-docstring">"""Gradient of the function at beta.</tt> </tt>
<a name="L203"></a><tt class="py-lineno">203</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L204"></a><tt class="py-lineno">204</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Gradient".</tt> </tt>
<a name="L205"></a><tt class="py-lineno">205</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L206"></a><tt class="py-lineno">206</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L207"></a><tt class="py-lineno">207</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L208"></a><tt class="py-lineno">208</tt>  <tt class="py-line"><tt class="py-docstring">        beta : The point at which to evaluate the gradient.</tt> </tt>
<a name="L209"></a><tt class="py-lineno">209</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L210"></a><tt class="py-lineno">210</tt>  <tt class="py-line">        <tt class="py-name">Xbeta</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt id="link-14" class="py-name"><a title="parsimony.datasets.simulated.beta" class="py-name" href="#" onclick="return doclink('link-14', 'beta', 'link-5');">beta</a></tt><tt class="py-op">)</tt> </tt>
<a name="L211"></a><tt class="py-lineno">211</tt>  <tt class="py-line">        <tt class="py-name">pi</tt> <tt class="py-op">=</tt> <tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-op">(</tt><tt class="py-number">1.0</tt> <tt class="py-op">+</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">exp</tt><tt class="py-op">(</tt><tt class="py-op">-</tt><tt class="py-name">Xbeta</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L212"></a><tt class="py-lineno">212</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">-</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">T</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">weights</tt> <tt class="py-op">*</tt> <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt> <tt class="py-op">-</tt> <tt class="py-name">pi</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">*</tt> <tt id="link-15" class="py-name"><a title="parsimony.datasets.simulated.beta" class="py-name" href="#" onclick="return doclink('link-15', 'beta', 'link-5');">beta</a></tt> </tt>
</div><a name="L213"></a><tt class="py-lineno">213</tt>  <tt class="py-line"><tt class="py-comment">#        return -np.dot(self.X.T,</tt> </tt>
<a name="L214"></a><tt class="py-lineno">214</tt>  <tt class="py-line"><tt class="py-comment">#                       np.dot(self.W, (self.y - pi))) \</tt> </tt>
<a name="L215"></a><tt class="py-lineno">215</tt>  <tt class="py-line"><tt class="py-comment">#                       + self.k * beta</tt> </tt>
<a name="L216"></a><tt class="py-lineno">216</tt>  <tt class="py-line"> </tt>
<a name="RidgeLogisticRegression.L"></a><div id="RidgeLogisticRegression.L-def"><a name="L217"></a><tt class="py-lineno">217</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression.L-toggle" onclick="return toggle('RidgeLogisticRegression.L');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html#L">L</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression.L-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeLogisticRegression.L-expanded"><a name="L218"></a><tt class="py-lineno">218</tt>  <tt class="py-line">        <tt class="py-docstring">"""Lipschitz constant of the gradient.</tt> </tt>
<a name="L219"></a><tt class="py-lineno">219</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L220"></a><tt class="py-lineno">220</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "LipschitzContinuousGradient".</tt> </tt>
<a name="L221"></a><tt class="py-lineno">221</tt>  <tt class="py-line"><tt class="py-docstring">        max eigen value of (1/4 Xt W X)</tt> </tt>
<a name="L222"></a><tt class="py-lineno">222</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L223"></a><tt class="py-lineno">223</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">lipschitz</tt> <tt class="py-op">==</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L224"></a><tt class="py-lineno">224</tt>  <tt class="py-line">            <tt class="py-comment"># pi(x) * (1 - pi(x)) &lt;= 0.25 = 0.5 * 0.5</tt> </tt>
<a name="L225"></a><tt class="py-lineno">225</tt>  <tt class="py-line">            <tt class="py-name">PWX</tt> <tt class="py-op">=</tt> <tt class="py-number">0.5</tt> <tt class="py-op">*</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sqrt</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">weights</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt>  <tt class="py-comment"># TODO: CHECK WITH FOUAD</tt> </tt>
<a name="L226"></a><tt class="py-lineno">226</tt>  <tt class="py-line">            <tt class="py-comment"># PW = 0.5 * np.eye(self.X.shape[0]) ## miss np.sqrt(self.W)</tt> </tt>
<a name="L227"></a><tt class="py-lineno">227</tt>  <tt class="py-line">            <tt class="py-comment">#PW = 0.5 * np.sqrt(self.W)</tt> </tt>
<a name="L228"></a><tt class="py-lineno">228</tt>  <tt class="py-line">            <tt class="py-comment">#PWX = np.dot(PW, self.X)</tt> </tt>
<a name="L229"></a><tt class="py-lineno">229</tt>  <tt class="py-line">            <tt class="py-comment"># TODO: Use FastSVD for speedup!</tt> </tt>
<a name="L230"></a><tt class="py-lineno">230</tt>  <tt class="py-line">            <tt class="py-name">s</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">linalg</tt><tt class="py-op">.</tt><tt class="py-name">svd</tt><tt class="py-op">(</tt><tt class="py-name">PWX</tt><tt class="py-op">,</tt> <tt class="py-name">full_matrices</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">,</tt> <tt class="py-name">compute_uv</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt> </tt>
<a name="L231"></a><tt class="py-lineno">231</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">lipschitz</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt> <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt>  <tt class="py-comment"># TODO: CHECK</tt> </tt>
<a name="L232"></a><tt class="py-lineno">232</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">lipschitz</tt> </tt>
</div></div><a name="L233"></a><tt class="py-lineno">233</tt>  <tt class="py-line"><tt class="py-comment">#        return self.lambda_max()</tt> </tt>
<a name="AnonymousFunction"></a><div id="AnonymousFunction-def"><a name="L234"></a><tt class="py-lineno">234</tt>  <tt class="py-line"> </tt>
<a name="L235"></a><tt class="py-lineno">235</tt>  <tt class="py-line"><tt class="py-comment">#    def lambda_max(self):</tt> </tt>
<a name="L236"></a><tt class="py-lineno">236</tt>  <tt class="py-line"><tt class="py-comment">#        """Largest eigenvalue of the corresponding covariance matrix.</tt> </tt>
<a name="L237"></a><tt class="py-lineno">237</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L238"></a><tt class="py-lineno">238</tt>  <tt class="py-line"><tt class="py-comment">#        From the interface "Eigenvalues".</tt> </tt>
<a name="L239"></a><tt class="py-lineno">239</tt>  <tt class="py-line"><tt class="py-comment">#        """</tt> </tt>
<a name="L240"></a><tt class="py-lineno">240</tt>  <tt class="py-line"><tt class="py-comment">#        if self._lambda_max is None:</tt> </tt>
<a name="L241"></a><tt class="py-lineno">241</tt>  <tt class="py-line"><tt class="py-comment">#            s = np.linalg.svd(self.X, full_matrices=False, compute_uv=False)</tt> </tt>
<a name="L242"></a><tt class="py-lineno">242</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L243"></a><tt class="py-lineno">243</tt>  <tt class="py-line"><tt class="py-comment">#            self._lambda_max = np.max(s) ** 2.0</tt> </tt>
<a name="L244"></a><tt class="py-lineno">244</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L245"></a><tt class="py-lineno">245</tt>  <tt class="py-line"><tt class="py-comment">#            if len(s) &lt; self.X.shape[1]:</tt> </tt>
<a name="L246"></a><tt class="py-lineno">246</tt>  <tt class="py-line"><tt class="py-comment">#                self._lambda_min = 0.0</tt> </tt>
<a name="L247"></a><tt class="py-lineno">247</tt>  <tt class="py-line"><tt class="py-comment">#            else:</tt> </tt>
<a name="L248"></a><tt class="py-lineno">248</tt>  <tt class="py-line"><tt class="py-comment">#                self._lambda_min = np.min(s) ** 2.0</tt> </tt>
<a name="L249"></a><tt class="py-lineno">249</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L250"></a><tt class="py-lineno">250</tt>  <tt class="py-line"><tt class="py-comment">#        return self._lambda_max + self.k</tt> </tt>
<a name="L251"></a><tt class="py-lineno">251</tt>  <tt class="py-line"> </tt>
<a name="L252"></a><tt class="py-lineno">252</tt>  <tt class="py-line"> </tt>
<a name="L253"></a><tt class="py-lineno">253</tt> <a class="py-toggle" href="#" id="AnonymousFunction-toggle" onclick="return toggle('AnonymousFunction');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="parsimony.functions.losses.AnonymousFunction-class.html">AnonymousFunction</a><tt class="py-op">(</tt><tt class="py-base-class">interfaces</tt><tt class="py-op">.</tt><tt class="py-base-class">AtomicFunction</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="AnonymousFunction-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="AnonymousFunction-expanded"><a name="L254"></a><tt class="py-lineno">254</tt>  <tt class="py-line"> </tt>
<a name="AnonymousFunction.__init__"></a><div id="AnonymousFunction.__init__-def"><a name="L255"></a><tt class="py-lineno">255</tt> <a class="py-toggle" href="#" id="AnonymousFunction.__init__-toggle" onclick="return toggle('AnonymousFunction.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.AnonymousFunction-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">f</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="AnonymousFunction.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="AnonymousFunction.__init__-expanded"><a name="L256"></a><tt class="py-lineno">256</tt>  <tt class="py-line"> </tt>
<a name="L257"></a><tt class="py-lineno">257</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_f</tt> <tt class="py-op">=</tt> <tt id="link-16" class="py-name" targets="Method parsimony._functions.AnonymousFunction.f()=parsimony._functions.AnonymousFunction-class.html#f,Method parsimony._functions.CombinedProjectionOperator.f()=parsimony._functions.CombinedProjectionOperator-class.html#f,Method parsimony._functions.Function.f()=parsimony._functions.Function-class.html#f,Method parsimony._functions.GeneralisedMultiblock.f()=parsimony._functions.GeneralisedMultiblock-class.html#f,Method parsimony._functions.GroupLassoOverlap.f()=parsimony._functions.GroupLassoOverlap-class.html#f,Method parsimony._functions.L1.f()=parsimony._functions.L1-class.html#f,Method parsimony._functions.LatentVariableCovariance.f()=parsimony._functions.LatentVariableCovariance-class.html#f,Method parsimony._functions.QuadraticConstraint.f()=parsimony._functions.QuadraticConstraint-class.html#f,Method parsimony._functions.RGCCAConstraint.f()=parsimony._functions.RGCCAConstraint-class.html#f,Method parsimony._functions.RR_L1_GL.f()=parsimony._functions.RR_L1_GL-class.html#f,Method parsimony._functions.RR_L1_TV.f()=parsimony._functions.RR_L1_TV-class.html#f,Method parsimony._functions.RR_SmoothedL1TV.f()=parsimony._functions.RR_SmoothedL1TV-class.html#f,Method parsimony._functions.RidgeLogisticRegression.f()=parsimony._functions.RidgeLogisticRegression-class.html#f,Method parsimony._functions.RidgeRegression.f()=parsimony._functions.RidgeRegression-class.html#f,Method parsimony._functions.SmoothedL1.f()=parsimony._functions.SmoothedL1-class.html#f,Method parsimony._functions.SmoothedL1TV.f()=parsimony._functions.SmoothedL1TV-class.html#f,Method parsimony._functions.SufficientDescentCondition.f()=parsimony._functions.SufficientDescentCondition-class.html#f,Method parsimony._functions.TotalVariation.f()=parsimony._functions.TotalVariation-class.html#f,Method parsimony.functions.interfaces.CombinedProjectionOperator.f()=parsimony.functions.interfaces.CombinedProjectionOperator-class.html#f,Method parsimony.functions.interfaces.Function.f()=parsimony.functions.interfaces.Function-class.html#f,Method parsimony.functions.losses.AnonymousFunction.f()=parsimony.functions.losses.AnonymousFunction-class.html#f,Method parsimony.functions.losses.RidgeLogisticRegression.f()=parsimony.functions.losses.RidgeLogisticRegression-class.html#f,Method parsimony.functions.losses.RidgeRegression.f()=parsimony.functions.losses.RidgeRegression-class.html#f,Method parsimony.functions.multiblock.losses.GeneralisedMultiblock.f()=parsimony.functions.multiblock.losses.GeneralisedMultiblock-class.html#f,Method parsimony.functions.multiblock.losses.LatentVariableCovariance.f()=parsimony.functions.multiblock.losses.LatentVariableCovariance-class.html#f,Method parsimony.functions.nesterov.L1.L1.f()=parsimony.functions.nesterov.L1.L1-class.html#f,Method parsimony.functions.nesterov.L1TV.L1TV.f()=parsimony.functions.nesterov.L1TV.L1TV-class.html#f,Method parsimony.functions.nesterov.gl.GroupLassoOverlap.f()=parsimony.functions.nesterov.gl.GroupLassoOverlap-class.html#f,Method parsimony.functions.nesterov.tv.TotalVariation.f()=parsimony.functions.nesterov.tv.TotalVariation-class.html#f,Method parsimony.functions.objectives.functions.CombinedFunction.f()=parsimony.functions.objectives.functions.CombinedFunction-class.html#f,Method parsimony.functions.objectives.functions.RR_L1_GL.f()=parsimony.functions.objectives.functions.RR_L1_GL-class.html#f,Method parsimony.functions.objectives.functions.RR_L1_TV.f()=parsimony.functions.objectives.functions.RR_L1_TV-class.html#f,Method parsimony.functions.objectives.functions.RR_SmoothedL1TV.f()=parsimony.functions.objectives.functions.RR_SmoothedL1TV-class.html#f,Method parsimony.functions.penalties.L1.f()=parsimony.functions.penalties.L1-class.html#f,Method parsimony.functions.penalties.L2.f()=parsimony.functions.penalties.L2-class.html#f,Method parsimony.functions.penalties.QuadraticConstraint.f()=parsimony.functions.penalties.QuadraticConstraint-class.html#f,Method parsimony.functions.penalties.RGCCAConstraint.f()=parsimony.functions.penalties.RGCCAConstraint-class.html#f,Method parsimony.functions.penalties.SufficientDescentCondition.f()=parsimony.functions.penalties.SufficientDescentCondition-class.html#f,Method parsimony.functions.penalties.ZeroFunction.f()=parsimony.functions.penalties.ZeroFunction-class.html#f"><a title="parsimony._functions.AnonymousFunction.f
parsimony._functions.CombinedProjectionOperator.f
parsimony._functions.Function.f
parsimony._functions.GeneralisedMultiblock.f
parsimony._functions.GroupLassoOverlap.f
parsimony._functions.L1.f
parsimony._functions.LatentVariableCovariance.f
parsimony._functions.QuadraticConstraint.f
parsimony._functions.RGCCAConstraint.f
parsimony._functions.RR_L1_GL.f
parsimony._functions.RR_L1_TV.f
parsimony._functions.RR_SmoothedL1TV.f
parsimony._functions.RidgeLogisticRegression.f
parsimony._functions.RidgeRegression.f
parsimony._functions.SmoothedL1.f
parsimony._functions.SmoothedL1TV.f
parsimony._functions.SufficientDescentCondition.f
parsimony._functions.TotalVariation.f
parsimony.functions.interfaces.CombinedProjectionOperator.f
parsimony.functions.interfaces.Function.f
parsimony.functions.losses.AnonymousFunction.f
parsimony.functions.losses.RidgeLogisticRegression.f
parsimony.functions.losses.RidgeRegression.f
parsimony.functions.multiblock.losses.GeneralisedMultiblock.f
parsimony.functions.multiblock.losses.LatentVariableCovariance.f
parsimony.functions.nesterov.L1.L1.f
parsimony.functions.nesterov.L1TV.L1TV.f
parsimony.functions.nesterov.gl.GroupLassoOverlap.f
parsimony.functions.nesterov.tv.TotalVariation.f
parsimony.functions.objectives.functions.CombinedFunction.f
parsimony.functions.objectives.functions.RR_L1_GL.f
parsimony.functions.objectives.functions.RR_L1_TV.f
parsimony.functions.objectives.functions.RR_SmoothedL1TV.f
parsimony.functions.penalties.L1.f
parsimony.functions.penalties.L2.f
parsimony.functions.penalties.QuadraticConstraint.f
parsimony.functions.penalties.RGCCAConstraint.f
parsimony.functions.penalties.SufficientDescentCondition.f
parsimony.functions.penalties.ZeroFunction.f" class="py-name" href="#" onclick="return doclink('link-16', 'f', 'link-16');">f</a></tt> </tt>
</div><a name="L258"></a><tt class="py-lineno">258</tt>  <tt class="py-line"> </tt>
<a name="AnonymousFunction.f"></a><div id="AnonymousFunction.f-def"><a name="L259"></a><tt class="py-lineno">259</tt> <a class="py-toggle" href="#" id="AnonymousFunction.f-toggle" onclick="return toggle('AnonymousFunction.f');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.AnonymousFunction-class.html#f">f</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="AnonymousFunction.f-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="AnonymousFunction.f-expanded"><a name="L260"></a><tt class="py-lineno">260</tt>  <tt class="py-line"> </tt>
<a name="L261"></a><tt class="py-lineno">261</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_f</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L262"></a><tt class="py-lineno">262</tt>  <tt class="py-line"> </tt><script type="text/javascript">
<!--
expandto(location.href);
// -->
</script>
</pre>
<br />
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="parsimony-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

      <th class="navbar" width="100%"></th>
  </tr>
</table>
<table border="0" cellpadding="0" cellspacing="0" width="100%%">
  <tr>
    <td align="left" class="footer">
    Generated by Epydoc 3.0.1 on Fri Feb 21 17:38:26 2014
    </td>
    <td align="right" class="footer">
      <a target="mainFrame" href="http://epydoc.sourceforge.net"
        >http://epydoc.sourceforge.net</a>
    </td>
  </tr>
</table>

<script type="text/javascript">
  <!--
  // Private objects are initially displayed (because if
  // javascript is turned off then we want them to be
  // visible); but by default, we want to hide them.  So hide
  // them unless we have a cookie that says to show them.
  checkCookie();
  // -->
</script>
</body>
</html>
